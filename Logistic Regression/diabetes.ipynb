{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "a20a28e580a0151ea3c2581529936b24eb0b60772cb225affd8463079d4ed54d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import scipy \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import copy\n",
    "\n",
    "#importing required modules, scipy to do the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"DataSets/diabetes-dataset.csv\")\n",
    "#data has been imported \n",
    "#creation of train test and outcome datasets\n",
    "x_train=copy.copy(data)\n",
    "x_train.drop(['Outcome'],axis=1,inplace=True)\n",
    "y_train=copy.copy(data)\n",
    "y_train.drop(['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age'],axis=1,inplace=True)\n",
    "y_train=y_train.to_numpy()\n",
    "x_train=x_train.to_numpy()\n",
    "# y_train=y_train\n",
    "# x_train=x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8, 2000)"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "#standardising the train dataset\n",
    "x_train=x_train/ x_train.std()\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializer for w and b\n",
    "\n",
    "def init(dim):\n",
    "    w=np.zeros((dim,1))\n",
    "    b=0.0\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward and backward propagation\n",
    "\n",
    "def propagate(w,b,X,Y):\n",
    "    #get number of columns\n",
    "    m=X.shape[0]\n",
    "\n",
    "    #computing activation function\n",
    "    A=sigmoid(np.dot(w.T,X)+b)\n",
    "    #computing cost function\n",
    "\n",
    "    cost=- (1/m)*np.sum((Y*np.log(A))+(1-Y)*(1-np.log(A)))\n",
    "\n",
    "    #backward propagation:\n",
    "    dw=(np.dot(X,(A-Y).T))/m\n",
    "    db=np.sum(A-Y)/m \n",
    "\n",
    "    cost=np.squeeze(np.array(cost))\n",
    "\n",
    "    grads = {\n",
    "        \"dw\": dw,\n",
    "        \"db\": db\n",
    "    }\n",
    "    return grads,cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#updating the parameters using gradient descent after each epoch\n",
    "\n",
    "def optimize(w,b,X,Y,num_iter,learn_rate,print_cost=False):\n",
    "    costs=[]\n",
    "    for i in range(num_iter): #number of epochs\n",
    "        grads,cost=propagate(w,b,X,Y)\n",
    "\n",
    "        dw=grads[\"dw\"]\n",
    "        db=grads[\"db\"]\n",
    "\n",
    "        w=w-(learn_rate*dw)\n",
    "        b=b-(learn_rate*db)\n",
    "\n",
    "        if i%100==0:\n",
    "            costs.append(cost) #logging the cost\n",
    "            if print_cost: \n",
    "                print(\"Cost after\",i,\" iterations is =\",cost)\n",
    "        \n",
    "    params={\n",
    "        \"w\":w,\n",
    "        \"b\":b\n",
    "    }\n",
    "\n",
    "    grads={\n",
    "        \"dw\":dw,\n",
    "        \"db\":db\n",
    "    }\n",
    "\n",
    "    return params,grads,costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the created algorithm to predict new algorithms \n",
    "\n",
    "def predict(w,b,X):\n",
    "    m=X.shape[1]\n",
    "    Y_prediction=np.zeros((1,m))\n",
    "    #w=w.reshape(X.shape[0],1)\n",
    "\n",
    "    #forward pass\n",
    "    A=sigmoid(np.dot(w.T,X)+b)\n",
    "    for i in range(A.shape[1]):\n",
    "        Y_prediction[0, i] = 1 if A[0,i] >=0.5 else 0\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a wrapper class\n",
    "\n",
    "def model(X_train,Y_train,X_test,Y_test,num_iter=1000,learn_rate=0.5,print_cost=True):\n",
    "    w,b=init(X_train.shape[0])\n",
    "    params,grads,costs=optimize(w,b,X_train,Y_train,num_iter,learn_rate,print_cost)\n",
    "    w=params[\"w\"]\n",
    "    b=params[\"b\"]\n",
    "    Y_prediction_test=predict(w,b,X_test)\n",
    "    Y_prediction_train=predict(w,b,X_train)\n",
    "\n",
    "    print(\"Train accuracy: {} %\".format(100-np.mean(np.abs(Y_prediction_train-Y_train))*100))\n",
    "    print(\"Test accuracy: {} %\".format(100-np.mean(np.abs(Y_prediction_test-Y_test))*100))\n",
    "\n",
    "    d = {\"costs\": costs,\n",
    "        \"Y_prediction_test\": Y_prediction_test, \n",
    "        \"Y_prediction_train\" : Y_prediction_train, \n",
    "        \"w\" : w, \n",
    "        \"b\" : b,\n",
    "        \"learning_rate\" : learn_rate,\n",
    "        \"num_iterations\": num_iter}\n",
    "    \n",
    "    return d\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cost after 0  iterations is = -7.016276072455542\n",
      "Cost after 100  iterations is = -60.443771263026264\n",
      "Cost after 200  iterations is = -75.1245986053976\n",
      "Cost after 300  iterations is = -86.48767708377011\n",
      "Cost after 400  iterations is = -95.99064233814686\n",
      "Cost after 500  iterations is = -104.23935324199883\n",
      "Cost after 600  iterations is = -111.57294137851503\n",
      "Cost after 700  iterations is = -118.20672025686561\n",
      "Cost after 800  iterations is = -124.28736956792822\n",
      "Cost after 900  iterations is = -129.91963074033293\n",
      "Cost after 1000  iterations is = -135.18095909684982\n",
      "Cost after 1100  iterations is = -140.13023603797205\n",
      "Cost after 1200  iterations is = -144.8132492397551\n",
      "Cost after 1300  iterations is = -149.26629023595976\n",
      "Cost after 1400  iterations is = -153.51859814689044\n",
      "Cost after 1500  iterations is = -157.59406726977173\n",
      "Cost after 1600  iterations is = -161.51246931806975\n",
      "Cost after 1700  iterations is = -165.29034665160222\n",
      "Cost after 1800  iterations is = -168.94167708120702\n",
      "Cost after 1900  iterations is = -172.4783767296115\n",
      "Train accuracy: 34.2 %\n",
      "Test accuracy: 34.2 %\n"
     ]
    }
   ],
   "source": [
    "log_reg_mod=model(x_train,y_train,x_train,y_train,num_iter=2000,learn_rate=0.0005,print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}